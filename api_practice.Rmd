---
title: "Practice retrieving data from an API"
author: "JP"
date: "2022-08-24"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

attach libraries 
```{r}
library(tidyverse) 
library(dataRetrieval)
library(here)
```

# Task 1: stream flow data

practice a tiny bit with their example: 
```{r}
# Choptank River near Greensboro, MD
siteNumber <- "01491000" 
ChoptankInfo <- readNWISsite(siteNumber)
parameterCd <- "00060"

#Raw daily data:
rawDailyData <- readNWISdv(siteNumber,parameterCd,
                      "1980-01-01","2010-01-01")

# Sample data Nitrate:
parameterCd <- "00618"
qwData <- readNWISqw(siteNumber,parameterCd,
                      "1980-01-01","2010-01-01")

pCode <- readNWISpCode(parameterCd)
```

Now try replacingthis stuff with the ventura river information
```{r}
site_number <- "11118500"
ventura_info <- readNWISsite(site_number) 
parameter <- "00060"

#Raw daily data:
raw_ventura_data <- readNWISdv(site_number,parameter,
                      "2019-10-01","2020-10-05").  #seems like this is the important thing that we need

ventu_code <- readNWISpCode(parameter)
```

Now you can graph the discharge (y) and time (x) 
```{r}
ggplot(data = raw_ventura_data, aes(x = Date, y = X_00060_00003)) +
  geom_line()
```

# Task 2 Alaska demographics 

using the package metajam to download and read in the data 
two step process so you can cache updated data (weird format)
```{r}
# set inputs
data_obj <- "https://knb.ecoinformatics.org/knb/d1/mn/v2/object/urn%3Auuid%3A7fc6f6db-c5ea-426a-a743-1f2edafb43b8"
path <- "~/EDS214/EDS214_day3"
# download data and metadata
library(metajam)
download_d1_data(data_obj, path)
```

R won't let you run the meta data download more than once so start a new chunk 
```{r}
my_data <- read_d1_files("~/EDS214/EDS214_day3/doi_10.5063_F1CJ8BPH__household_language__csv")
```

Extract the dataset
```{r}
dataframe <- my_data$data
```

Write a piece of code that will compute the percentage of Alaskan household speaking only English for the year 2009 to 2015 and plot it on a graph

```{r}
#see the key in the website repository on github: brunj7/EDS... name of website
```

